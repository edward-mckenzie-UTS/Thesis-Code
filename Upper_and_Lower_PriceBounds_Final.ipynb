{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mzSqoU7tkWPy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras import regularizers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_paths(S0, r, sigma, T, N, M):\n",
        "    dt = float(T) / N\n",
        "    paths = np.zeros((N, M), np.float32)\n",
        "    paths[0] = S0\n",
        "    for t in range(1, N ):\n",
        "        rand = np.random.standard_normal(M)\n",
        "        paths[t] = paths[t - 1] * np.exp((r - 0.5 * sigma ** 2) * dt +\n",
        "                                         sigma * np.sqrt(dt) * rand)\n",
        "    return paths"
      ],
      "metadata": {
        "id": "n5NjW68kkZi_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSM_NN(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(LSM_NN, self).__init__()\n",
        "        self.fc1 = tf.keras.layers.Dense(50, activation='relu')\n",
        "        self.fc2 = tf.keras.layers.Dense(50, activation='relu')\n",
        "        self.fc3 = tf.keras.layers.Dense(50, activation='relu')\n",
        "        self.fc4 = tf.keras.layers.Dense(1, activation='linear')\n",
        "        self.fc5 = tf.keras.layers.Dense(1, activation='linear')\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "        continuation_val = self.fc4(x)\n",
        "        martingale_func = self.fc5(x)\n",
        "        return continuation_val, martingale_func"
      ],
      "metadata": {
        "id": "2gVVS4kWkjhl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def put_payoff(S, K):\n",
        "    return np.maximum(K - S, 0)"
      ],
      "metadata": {
        "id": "gSTqsL4ckoX8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def warm_start(model1, model2):\n",
        "    weights = [layer.get_weights() for layer in model1.layers if type(layer) is tf.keras.layers.Dense]\n",
        "    for i, layer in enumerate(model2.layers):\n",
        "      if type(layer) is tf.keras.layers.Dense:\n",
        "          layer.set_weights(weights.pop(0))\n",
        "\n",
        "    return model2"
      ],
      "metadata": {
        "id": "A-nCt7a7ky0I"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "S0 = 36\n",
        "K = 40\n",
        "vol = 0.2\n",
        "rf = 0.06\n",
        "steps = 50\n",
        "paths = 10000\n",
        "T = 1\n",
        "dt = T/steps\n",
        "N = steps\n",
        "\n",
        "discount_factor = np.exp(-rf * dt)\n",
        "\n",
        "S = gen_paths(S0, rf, vol, T, steps, paths)\n",
        "\n",
        "payoff = put_payoff(S[-1], K)\n",
        "upper_price = payoff.copy()\n",
        "lower_price = payoff.copy()\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=False)"
      ],
      "metadata": {
        "id": "Q1cJFzU9lEvk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize data structures\n",
        "cont_store = []\n",
        "mart_store = []\n",
        "lower_store = []\n",
        "upper_store = []"
      ],
      "metadata": {
        "id": "W1hst0NOlIVD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def create_and_initialize_model(paths, model=None):\n",
        "    new_model = LSM_NN()\n",
        "    new_model.build(input_shape=(paths, 1))\n",
        "    if model is not None:\n",
        "        new_model = warm_start(model, new_model)\n",
        "    return new_model\n",
        "\n",
        "def train_model(model, X, y, dW, kf, optimizer, loss_fn):\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(50):\n",
        "        epoch_val_loss = 0.0\n",
        "        for train_idx, val_idx in kf.split(X):\n",
        "            # Splitting dataset\n",
        "            X_train, X_val = tf.gather(X, train_idx), tf.gather(X, val_idx)\n",
        "            y_train, y_val = tf.gather(y, train_idx), tf.gather(y, val_idx)\n",
        "            dW_train, dW_val = tf.gather(dW, train_idx), tf.gather(dW, val_idx)\n",
        "\n",
        "            # Training step\n",
        "            loss_train = train_step(model, X_train, y_train, dW_train, optimizer, loss_fn)\n",
        "\n",
        "            # Validation step\n",
        "            loss_val = validate_step(model, X_val, y_val, dW_val, loss_fn)\n",
        "            epoch_val_loss += loss_val.numpy()\n",
        "\n",
        "        epoch_val_loss /= kf.get_n_splits()\n",
        "\n",
        "        # Early stopping condition\n",
        "        if epoch_val_loss < best_val_loss:\n",
        "            best_val_loss = epoch_val_loss\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "\n",
        "        if epochs_no_improve == 5:\n",
        "            break\n",
        "\n",
        "    return model, epoch_val_loss\n",
        "\n",
        "def train_step(model, X_train, y_train, dW_train, optimizer, loss_fn):\n",
        "    with tf.GradientTape() as tape:\n",
        "        prediction_train = model_prediction(model, X_train, dW_train)\n",
        "        loss_train = loss_fn(y_true=tf.squeeze(y_train), y_pred=prediction_train)\n",
        "\n",
        "    grads = tape.gradient(loss_train, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "    return loss_train\n",
        "\n",
        "def validate_step(model, X_val, y_val, dW_val, loss_fn):\n",
        "    prediction_val = model_prediction(model, X_val, dW_val)\n",
        "    loss_val = loss_fn(y_true=tf.squeeze(y_val), y_pred=prediction_val)\n",
        "    return loss_val\n",
        "\n",
        "def model_prediction(model, X, dW):\n",
        "    continuation, martingale = model(X, training=False)\n",
        "    return tf.add(continuation, martingale * dW)\n",
        "\n",
        "# Main simulation loop\n",
        "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.01)\n",
        "loss_fn = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "for t in range(N - 1, -1, -1):\n",
        "    tf.random.set_seed(123)\n",
        "    print(f\"Time step {t}\")\n",
        "\n",
        "    # Initializing the model\n",
        "    if t == N - 1:\n",
        "        y_value = discount_factor * payoff\n",
        "    else:\n",
        "        y_value = discount_factor * lower_price\n",
        "\n",
        "    model = create_and_initialize_model(paths, model if t != 49 else None)\n",
        "\n",
        "    # Preparing data\n",
        "    X = tf.convert_to_tensor(S[t], dtype=tf.float32)[:, tf.newaxis]\n",
        "    y = tf.convert_to_tensor(y_value, dtype=tf.float32)[:, tf.newaxis]\n",
        "    dW = np.sqrt(dt) * np.random.normal(size=paths)\n",
        "    dW = tf.convert_to_tensor(dW, dtype=np.float32)[:, tf.newaxis]\n",
        "\n",
        "    # Training the model\n",
        "    model, epoch_val_loss = train_model(model, X, y, dW, kf, optimizer, loss_fn)\n",
        "    print(f\"Val Loss for time step {t}: {epoch_val_loss}\")\n",
        "\n",
        "    # Post-training calculations\n",
        "    continuation_value, martingale_function = model(X, training=False)\n",
        "    if t == N - 1:\n",
        "        upper_price = y_value - tf.squeeze(martingale_function).numpy() * tf.squeeze(dW).numpy()\n",
        "    else:\n",
        "        upper_price = discount_factor * upper_store[-1] - tf.squeeze(martingale_function).numpy() * tf.squeeze(dW).numpy()\n",
        "\n",
        "    lower_price = y_value - tf.squeeze(martingale_function).numpy() * tf.squeeze(dW).numpy()\n",
        "\n",
        "    # Updating prices\n",
        "    upper_price = np.where(put_payoff(S[t], K) > upper_price, put_payoff(S[t], K), upper_price)\n",
        "    lower_price = np.where(put_payoff(S[t], K) > tf.squeeze(continuation_value).numpy(), put_payoff(S[t], K), lower_price)\n",
        "\n",
        "    # Storing values\n",
        "    cont_store.append(tf.squeeze(continuation_value).numpy())\n",
        "    mart_store.append(tf.squeeze(martingale_function).numpy())\n",
        "    lower_store.append(lower_price)\n",
        "    upper_store.append(upper_price)\n"
      ],
      "metadata": {
        "id": "vYOyDXvelLi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "upper_price = np.mean(upper_store)\n",
        "upper_price"
      ],
      "metadata": {
        "id": "KdUekanfn0_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lower_price = np.mean(lower_store)\n",
        "lower_price"
      ],
      "metadata": {
        "id": "a54qu2OAqqVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jRRpJFuQqvMQ"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}