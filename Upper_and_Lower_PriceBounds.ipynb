{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mzSqoU7tkWPy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras import regularizers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_paths(S0, r, sigma, T, N, M):\n",
        "    dt = float(T) / N\n",
        "    paths = np.zeros((N, M), np.float32)\n",
        "    paths[0] = S0\n",
        "    for t in range(1, N ):\n",
        "        rand = np.random.standard_normal(M)\n",
        "        paths[t] = paths[t - 1] * np.exp((r - 0.5 * sigma ** 2) * dt +\n",
        "                                         sigma * np.sqrt(dt) * rand)\n",
        "    return paths"
      ],
      "metadata": {
        "id": "n5NjW68kkZi_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSM_NN(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(LSM_NN, self).__init__()\n",
        "        self.fc1 = tf.keras.layers.Dense(50, activation='relu')\n",
        "        self.fc2 = tf.keras.layers.Dense(50, activation='relu')\n",
        "        self.fc3 = tf.keras.layers.Dense(50, activation='relu')\n",
        "        self.fc4 = tf.keras.layers.Dense(1, activation='linear')\n",
        "        self.fc5 = tf.keras.layers.Dense(1, activation='linear')\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "        continuation_val = self.fc4(x)\n",
        "        martingale_func = self.fc5(x)\n",
        "        return continuation_val, martingale_func"
      ],
      "metadata": {
        "id": "2gVVS4kWkjhl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def put_payoff(S, K):\n",
        "    return np.maximum(K - S, 0)"
      ],
      "metadata": {
        "id": "gSTqsL4ckoX8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def warm_start(model1, model2):\n",
        "    weights = [layer.get_weights() for layer in model1.layers if type(layer) is tf.keras.layers.Dense]\n",
        "    for i, layer in enumerate(model2.layers):\n",
        "      if type(layer) is tf.keras.layers.Dense:\n",
        "          layer.set_weights(weights.pop(0))\n",
        "\n",
        "    return model2"
      ],
      "metadata": {
        "id": "A-nCt7a7ky0I"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "S0 = 36\n",
        "K = 40\n",
        "vol = 0.2\n",
        "rf = 0.06\n",
        "steps = 50\n",
        "paths = 10000\n",
        "T = 1\n",
        "dt = T/steps\n",
        "N = steps\n",
        "\n",
        "discount_factor = np.exp(-rf * dt)\n",
        "\n",
        "S = gen_paths(S0, rf, vol, T, steps, paths)\n",
        "\n",
        "payoff = put_payoff(S[-1], K)\n",
        "upper_price = payoff.copy()\n",
        "lower_price = payoff.copy()\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=False)"
      ],
      "metadata": {
        "id": "Q1cJFzU9lEvk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize data structures\n",
        "cont_store = []\n",
        "mart_store = []\n",
        "lower_store = []\n",
        "upper_store = []"
      ],
      "metadata": {
        "id": "W1hst0NOlIVD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def create_and_initialize_model(paths, model=None):\n",
        "    new_model = LSM_NN()\n",
        "    new_model.build(input_shape=(paths, 1))\n",
        "    if model is not None:\n",
        "        new_model = warm_start(model, new_model)\n",
        "    return new_model\n",
        "\n",
        "def train_model(model, X, y, dW, kf, optimizer, loss_fn):\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(50):\n",
        "        epoch_val_loss = 0.0\n",
        "        for train_idx, val_idx in kf.split(X):\n",
        "            # Splitting dataset\n",
        "            X_train, X_val = tf.gather(X, train_idx), tf.gather(X, val_idx)\n",
        "            y_train, y_val = tf.gather(y, train_idx), tf.gather(y, val_idx)\n",
        "            dW_train, dW_val = tf.gather(dW, train_idx), tf.gather(dW, val_idx)\n",
        "\n",
        "            # Training step\n",
        "            loss_train = train_step(model, X_train, y_train, dW_train, optimizer, loss_fn)\n",
        "\n",
        "            # Validation step\n",
        "            loss_val = validate_step(model, X_val, y_val, dW_val, loss_fn)\n",
        "            epoch_val_loss += loss_val.numpy()\n",
        "\n",
        "        epoch_val_loss /= kf.get_n_splits()\n",
        "\n",
        "        # Early stopping condition\n",
        "        if epoch_val_loss < best_val_loss:\n",
        "            best_val_loss = epoch_val_loss\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "\n",
        "        if epochs_no_improve == 5:\n",
        "            break\n",
        "\n",
        "    return model, epoch_val_loss\n",
        "\n",
        "def train_step(model, X_train, y_train, dW_train, optimizer, loss_fn):\n",
        "    with tf.GradientTape() as tape:\n",
        "        prediction_train = model_prediction(model, X_train, dW_train)\n",
        "        loss_train = loss_fn(y_true=tf.squeeze(y_train), y_pred=prediction_train)\n",
        "\n",
        "    grads = tape.gradient(loss_train, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "    return loss_train\n",
        "\n",
        "def validate_step(model, X_val, y_val, dW_val, loss_fn):\n",
        "    prediction_val = model_prediction(model, X_val, dW_val)\n",
        "    loss_val = loss_fn(y_true=tf.squeeze(y_val), y_pred=prediction_val)\n",
        "    return loss_val\n",
        "\n",
        "def model_prediction(model, X, dW):\n",
        "    continuation, martingale = model(X, training=False)\n",
        "    return tf.add(continuation, martingale * dW)\n",
        "\n",
        "# Main simulation loop\n",
        "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.01)\n",
        "loss_fn = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "for t in range(49, -1, -1):\n",
        "    tf.random.set_seed(123)\n",
        "    print(f\"Time step {t}\")\n",
        "\n",
        "    # Initializing the model\n",
        "    if t == 49:\n",
        "        y_value = discount_factor * payoff\n",
        "    else:\n",
        "        y_value = discount_factor * lower_price\n",
        "\n",
        "    model = create_and_initialize_model(paths, model if t != 49 else None)\n",
        "\n",
        "    # Preparing data\n",
        "    X = tf.convert_to_tensor(S[t], dtype=tf.float32)[:, tf.newaxis]\n",
        "    y = tf.convert_to_tensor(y_value, dtype=tf.float32)[:, tf.newaxis]\n",
        "    dW = np.sqrt(dt) * np.random.normal(size=paths)\n",
        "    dW = tf.convert_to_tensor(dW, dtype=np.float32)[:, tf.newaxis]\n",
        "\n",
        "    # Training the model\n",
        "    model, epoch_val_loss = train_model(model, X, y, dW, kf, optimizer, loss_fn)\n",
        "    print(f\"Val Loss for time step {t}: {epoch_val_loss}\")\n",
        "\n",
        "    # Post-training calculations\n",
        "    continuation_value, martingale_function = model(X, training=False)\n",
        "    if t == 49:\n",
        "        upper_price = y_value - tf.squeeze(martingale_function).numpy() * tf.squeeze(dW).numpy()\n",
        "    else:\n",
        "        upper_price = discount_factor * upper_store[-1] - tf.squeeze(martingale_function).numpy() * tf.squeeze(dW).numpy()\n",
        "\n",
        "    lower_price = y_value - tf.squeeze(martingale_function).numpy() * tf.squeeze(dW).numpy()\n",
        "\n",
        "    # Updating prices\n",
        "    upper_price = np.where(put_payoff(S[t], K) > upper_price, put_payoff(S[t], K), upper_price)\n",
        "    lower_price = np.where(put_payoff(S[t], K) > tf.squeeze(continuation_value).numpy(), put_payoff(S[t], K), lower_price)\n",
        "\n",
        "    # Storing values\n",
        "    cont_store.append(tf.squeeze(continuation_value).numpy())\n",
        "    mart_store.append(tf.squeeze(martingale_function).numpy())\n",
        "    lower_store.append(lower_price)\n",
        "    upper_store.append(upper_price)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYOyDXvelLi1",
        "outputId": "f7a8df34-3e4a-4539-b14b-45603ceb272b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time step 49\n",
            "Val Loss for time step 49: 4.703009748458863\n",
            "Time step 48\n",
            "Val Loss for time step 48: 3.003720283508301\n",
            "Time step 47\n",
            "Val Loss for time step 47: 0.8928340554237366\n",
            "Time step 46\n",
            "Val Loss for time step 46: 0.6800436973571777\n",
            "Time step 45\n",
            "Val Loss for time step 45: 0.7824354052543641\n",
            "Time step 44\n",
            "Val Loss for time step 44: 0.8421796679496765\n",
            "Time step 43\n",
            "Val Loss for time step 43: 1.0151106238365173\n",
            "Time step 42\n",
            "Val Loss for time step 42: 0.9893122911453247\n",
            "Time step 41\n",
            "Val Loss for time step 41: 26.841675567626954\n",
            "Time step 40\n",
            "Val Loss for time step 40: 0.9021356463432312\n",
            "Time step 39\n",
            "Val Loss for time step 39: 0.9809213638305664\n",
            "Time step 38\n",
            "Val Loss for time step 38: 1.0319669008255006\n",
            "Time step 37\n",
            "Val Loss for time step 37: 1.15829496383667\n",
            "Time step 36\n",
            "Val Loss for time step 36: 1.2554038763046265\n",
            "Time step 35\n",
            "Val Loss for time step 35: 1.3531131267547607\n",
            "Time step 34\n",
            "Val Loss for time step 34: 1.4855570554733277\n",
            "Time step 33\n",
            "Val Loss for time step 33: 1.4547855854034424\n",
            "Time step 32\n",
            "Val Loss for time step 32: 1.5811893701553346\n",
            "Time step 31\n",
            "Val Loss for time step 31: 1.6689330339431763\n",
            "Time step 30\n",
            "Val Loss for time step 30: 1.7555100202560425\n",
            "Time step 29\n",
            "Val Loss for time step 29: 1.881953740119934\n",
            "Time step 28\n",
            "Val Loss for time step 28: 1.9521217823028565\n",
            "Time step 27\n",
            "Val Loss for time step 27: 2.0786431789398194\n",
            "Time step 26\n",
            "Val Loss for time step 26: 2.220148134231567\n",
            "Time step 25\n",
            "Val Loss for time step 25: 2.3348315715789796\n",
            "Time step 24\n",
            "Val Loss for time step 24: 2.3623745918273924\n",
            "Time step 23\n",
            "Val Loss for time step 23: 2.506158399581909\n",
            "Time step 22\n",
            "Val Loss for time step 22: 2.6457772731781004\n",
            "Time step 21\n",
            "Val Loss for time step 21: 2.8695985317230224\n",
            "Time step 20\n",
            "Val Loss for time step 20: 3.1365471363067625\n",
            "Time step 19\n",
            "Val Loss for time step 19: 3.224357795715332\n",
            "Time step 18\n",
            "Val Loss for time step 18: 3.2981913566589354\n",
            "Time step 17\n",
            "Val Loss for time step 17: 3.3884392261505125\n",
            "Time step 16\n",
            "Val Loss for time step 16: 3.4844510078430178\n",
            "Time step 15\n",
            "Val Loss for time step 15: 3.7327796459197997\n",
            "Time step 14\n",
            "Val Loss for time step 14: 3.935713052749634\n",
            "Time step 13\n",
            "Val Loss for time step 13: 3.858496379852295\n",
            "Time step 12\n",
            "Val Loss for time step 12: 3.945991945266724\n",
            "Time step 11\n",
            "Val Loss for time step 11: 4.044284963607788\n",
            "Time step 10\n",
            "Val Loss for time step 10: 4.411170864105225\n",
            "Time step 9\n",
            "Val Loss for time step 9: 4.753816604614258\n",
            "Time step 8\n",
            "Val Loss for time step 8: 4.78562707901001\n",
            "Time step 7\n",
            "Val Loss for time step 7: 5.21259298324585\n",
            "Time step 6\n",
            "Val Loss for time step 6: 5.586368656158447\n",
            "Time step 5\n",
            "Val Loss for time step 5: 6.039132881164551\n",
            "Time step 4\n",
            "Val Loss for time step 4: 6.350983619689941\n",
            "Time step 3\n",
            "Val Loss for time step 3: 6.559099006652832\n",
            "Time step 2\n",
            "Val Loss for time step 2: 6.714967155456543\n",
            "Time step 1\n",
            "Val Loss for time step 1: 7.075404357910156\n",
            "Time step 0\n",
            "Val Loss for time step 0: 6.6191558837890625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "upper_price = np.mean(upper_store)\n",
        "upper_price"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdUekanfn0_P",
        "outputId": "1390c1ec-f5f7-4b95-e75f-805409d7591b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.2188044"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lower_price = np.mean(lower_store)\n",
        "lower_price"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a54qu2OAqqVN",
        "outputId": "679767f5-2753-4e0f-d950-b0e4261cde70"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.360262"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jRRpJFuQqvMQ"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}